#!/usr/bin/env python3
"""
LLaVA-1.5-13Bæ¨¡å‹æƒé‡ä¸‹è½½è„šæœ¬
ä¸‹è½½åœ°å€: https://huggingface.co/liuhaotian/llava-v1.5-13b
"""

import os
import sys
import subprocess
import shutil
from pathlib import Path

def setup_directories():
    """è®¾ç½®ä¸‹è½½ç›®å½•å’Œç¼“å­˜ç›®å½•"""
    # ç›®æ ‡ç›®å½•
    target_dir = Path("/data/model/Inference_VLM/models-LLava-1.5-13B")
    
    # ç¼“å­˜ç›®å½•
    cache_dir = target_dir / ".cache"
    
    # åˆ›å»ºç›®å½•
    target_dir.mkdir(parents=True, exist_ok=True)
    cache_dir.mkdir(parents=True, exist_ok=True)
    
    print(f"ğŸ“ ç›®æ ‡ç›®å½•: {target_dir}")
    print(f"ğŸ“ ç¼“å­˜ç›®å½•: {cache_dir}")
    
    return target_dir, cache_dir

def check_disk_space():
    """æ£€æŸ¥ç£ç›˜ç©ºé—´æ˜¯å¦è¶³å¤Ÿ"""
    try:
        result = subprocess.run(["df", "-h", "/data"], capture_output=True, text=True)
        lines = result.stdout.strip().split('\n')
        if len(lines) > 1:
            parts = lines[1].split()
            if len(parts) >= 5:
                available = parts[3]
                print(f"ğŸ’¾ å¯ç”¨ç£ç›˜ç©ºé—´: {available}")
                return True
    except Exception as e:
        print(f"âš ï¸ æ— æ³•æ£€æŸ¥ç£ç›˜ç©ºé—´: {e}")
    
    return True

def download_with_huggingface_hub(model_name, target_dir, cache_dir):
    """ä½¿ç”¨huggingface_hubä¸‹è½½æ¨¡å‹"""
    try:
        from huggingface_hub import snapshot_download
        
        print(f"ğŸš€ å¼€å§‹ä¸‹è½½ {model_name}...")
        
        # è®¾ç½®ç¯å¢ƒå˜é‡
        os.environ['HF_HOME'] = str(cache_dir)
        os.environ['TRANSFORMERS_CACHE'] = str(cache_dir)
        
        # ä¸‹è½½æ¨¡å‹
        snapshot_download(
            repo_id=model_name,
            local_dir=target_dir,
            local_dir_use_symlinks=False,
            resume_download=True,
            allow_patterns=[
                "*.json",
                "*.bin",
                "*.model",
                "*.txt",
                "*.py",
                "*.md"
            ]
        )
        
        print(f"âœ… {model_name} ä¸‹è½½å®Œæˆ!")
        return True
        
    except ImportError:
        print("âŒ huggingface_hub æœªå®‰è£…ï¼Œå°è¯•ä½¿ç”¨gitä¸‹è½½")
        return False
    except Exception as e:
        print(f"âŒ ä¸‹è½½å¤±è´¥: {e}")
        return False

def download_with_git(model_name, target_dir):
    """ä½¿ç”¨gitä¸‹è½½æ¨¡å‹ï¼ˆå¤‡ç”¨æ–¹æ³•ï¼‰"""
    try:
        repo_url = f"https://huggingface.co/{model_name}"
        
        print(f"ğŸš€ ä½¿ç”¨gitä¸‹è½½ {model_name}...")
        
        # å…‹éš†ä»“åº“ï¼ˆä¸åŒ…å«å¤§æ–‡ä»¶ï¼‰
        result = subprocess.run([
            "git", "clone", repo_url, str(target_dir), "--depth", "1"
        ], capture_output=True, text=True)
        
        if result.returncode == 0:
            print("âœ… åŸºç¡€æ–‡ä»¶ä¸‹è½½å®Œæˆ")
            print("âš ï¸ éœ€è¦æ‰‹åŠ¨ä¸‹è½½å¤§æ–‡ä»¶ï¼Œè¯·ä½¿ç”¨git lfs pullæˆ–æ‰‹åŠ¨ä¸‹è½½æƒé‡æ–‡ä»¶")
            return True
        else:
            print(f"âŒ gitå…‹éš†å¤±è´¥: {result.stderr}")
            return False
            
    except Exception as e:
        print(f"âŒ gitä¸‹è½½å¤±è´¥: {e}")
        return False

def verify_download(target_dir):
    """éªŒè¯ä¸‹è½½çš„æ–‡ä»¶"""
    required_files = [
        "config.json",
        "pytorch_model.bin",
        "tokenizer.model",
        "tokenizer_config.json",
        "special_tokens_map.json"
    ]
    
    print("\nğŸ” éªŒè¯ä¸‹è½½æ–‡ä»¶...")
    
    missing_files = []
    for file in required_files:
        file_path = target_dir / file
        if file_path.exists():
            size = file_path.stat().st_size / (1024*1024)  # MB
            print(f"âœ… {file} ({size:.1f} MB)")
        else:
            missing_files.append(file)
            print(f"âŒ {file} ç¼ºå¤±")
    
    if missing_files:
        print(f"\nâš ï¸ ç¼ºå¤±æ–‡ä»¶: {missing_files}")
        print("è¯·æ‰‹åŠ¨ä¸‹è½½ç¼ºå¤±çš„æ–‡ä»¶")
        return False
    else:
        print("âœ… æ‰€æœ‰å¿…éœ€æ–‡ä»¶éƒ½å·²ä¸‹è½½")
        return True

def create_readme(target_dir):
    """åˆ›å»ºREADMEæ–‡ä»¶"""
    readme_content = """# LLaVA-1.5-13B æ¨¡å‹

## æ¨¡å‹ä¿¡æ¯
- **æ¨¡å‹åç§°**: LLaVA-1.5-13B
- **HuggingFace**: https://huggingface.co/liuhaotian/llava-v1.5-13b
- **å¤§å°**: çº¦26GB
- **æ¶æ„**: LLaVA (Large Language and Vision Assistant)

## ä½¿ç”¨æ–¹æ³•

```python
from transformers import LlavaForConditionalGeneration, AutoProcessor
import torch

# åŠ è½½æ¨¡å‹
model = LlavaForConditionalGeneration.from_pretrained(
    "/data/model/Inference_VLM/models-LLava-1.5-13B",
    torch_dtype=torch.float16,
    device_map="auto"
)

# åŠ è½½å¤„ç†å™¨
processor = AutoProcessor.from_pretrained(
    "/data/model/Inference_VLM/models-LLava-1.5-13B"
)
```

## ä¸‹è½½ä¿¡æ¯
- ä¸‹è½½æ—¶é—´: {download_time}
- ä¸‹è½½æ–¹å¼: huggingface_hub
- å­˜å‚¨ä½ç½®: {target_dir}
"""
    
    from datetime import datetime
    download_time = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    
    readme_path = target_dir / "README.md"
    with open(readme_path, "w", encoding="utf-8") as f:
        f.write(readme_content.format(
            download_time=download_time,
            target_dir=str(target_dir)
        ))
    
    print(f"ğŸ“„ READMEæ–‡ä»¶å·²åˆ›å»º: {readme_path}")

def main():
    """ä¸»å‡½æ•°"""
    print("=" * 60)
    print("ğŸš€ LLaVA-1.5-13B æ¨¡å‹ä¸‹è½½è„šæœ¬")
    print("=" * 60)
    
    # æ¨¡å‹åç§°
    model_name = "liuhaotian/llava-v1.5-13b"
    
    # è®¾ç½®ç›®å½•
    target_dir, cache_dir = setup_directories()
    
    # æ£€æŸ¥ç£ç›˜ç©ºé—´
    if not check_disk_space():
        print("âŒ ç£ç›˜ç©ºé—´ä¸è¶³ï¼Œè¯·æ¸…ç†ç©ºé—´åé‡è¯•")
        return
    
    # å°è¯•ä½¿ç”¨huggingface_hubä¸‹è½½
    success = download_with_huggingface_hub(model_name, target_dir, cache_dir)
    
    # å¦‚æœhuggingface_hubå¤±è´¥ï¼Œå°è¯•git
    if not success:
        print("\nğŸ”„ å°è¯•å¤‡ç”¨ä¸‹è½½æ–¹æ³•...")
        success = download_with_git(model_name, target_dir)
    
    # éªŒè¯ä¸‹è½½
    if success:
        verify_download(target_dir)
        create_readme(target_dir)
        
        print("\n" + "=" * 60)
        print("ğŸ‰ ä¸‹è½½å®Œæˆ!")
        print(f"ğŸ“ æ¨¡å‹ä½ç½®: {target_dir}")
        print("ğŸ’¡ ä½¿ç”¨æ–¹æ³•è¯·å‚è€ƒ README.md")
        print("=" * 60)
    else:
        print("\n" + "=" * 60)
        print("âŒ ä¸‹è½½å¤±è´¥")
        print("ğŸ’¡ è¯·æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–æ‰‹åŠ¨ä¸‹è½½")
        print("=" * 60)

if __name__ == "__main__":
    main()