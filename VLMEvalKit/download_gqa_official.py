#!/usr/bin/env python3
"""
ä¸‹è½½GQA benchmarkæ•°æ®é›† - å®˜æ–¹æ”¯æŒçš„ç‰ˆæœ¬
"""
import os
import sys

# è®¾ç½®ç¼“å­˜ç›®å½•ä¸ºå½“å‰ç›®å½•ä¸‹çš„hf_cache
os.environ['HF_HOME'] = os.path.join(os.getcwd(), 'hf_cache')
os.environ['TRANSFORMERS_CACHE'] = os.environ['HF_HOME']

print(f"HF_HOMEè®¾ç½®ä¸º: {os.environ['HF_HOME']}")
print(f"TRANSFORMERS_CACHEè®¾ç½®ä¸º: {os.environ['TRANSFORMERS_CACHE']}")

# ç¡®ä¿ç¼“å­˜ç›®å½•å­˜åœ¨
if not os.path.exists(os.environ['HF_HOME']):
    os.makedirs(os.environ['HF_HOME'])
    print(f"åˆ›å»ºç¼“å­˜ç›®å½•: {os.environ['HF_HOME']}")

# å¯¼å…¥vlmeval
from vlmeval.dataset import build_dataset

def download_gqa_dataset():
    """ä¸‹è½½GQAæ•°æ®é›†"""
    print("\n=== å¼€å§‹ä¸‹è½½GQA benchmark ===")
    
    # ä½¿ç”¨å®˜æ–¹æ”¯æŒçš„GQAæ•°æ®é›†åç§°
    dataset_name = 'GQA_TestDev_Balanced'
    print(f"æ•°æ®é›†åç§°: {dataset_name}")
    
    try:
        # å°è¯•é€šè¿‡HuggingFaceä¸‹è½½
        print("å°è¯•é€šè¿‡HuggingFaceä¸‹è½½...")
        dataset = build_dataset(dataset_name)
        
        if dataset is not None:
            print(f"âœ… æˆåŠŸæ„å»ºGQAæ•°æ®é›†: {dataset_name}")
            print(f"   æ•°æ®é›†ç±»å‹: {dataset.TYPE}")
            print(f"   æ•°æ®é›†æ¨¡æ€: {dataset.MODALITY}")
            print(f"   æ•°æ®é›†å¤§å°: {len(dataset.data)}")
            
            # æ˜¾ç¤ºæ•°æ®é›†çš„åŸºæœ¬ä¿¡æ¯
            if hasattr(dataset, 'data') and len(dataset.data) > 0:
                print("\næ•°æ®é›†æ ·æœ¬ç¤ºä¾‹:")
                sample = dataset.data.iloc[0]
                print(f"  ç´¢å¼•: {sample.get('index', 'N/A')}")
                print(f"  é—®é¢˜: {sample.get('question', 'N/A')[:100]}..." if 'question' in sample else "  é—®é¢˜å­—æ®µä¸å­˜åœ¨")
                if 'A' in sample and 'B' in sample:
                    print(f"  é€‰é¡¹A: {sample.get('A', 'N/A')[:50]}...")
                    print(f"  é€‰é¡¹B: {sample.get('B', 'N/A')[:50]}...")
                print(f"  ç­”æ¡ˆ: {sample.get('answer', 'N/A')}")
            
            return dataset
        else:
            print(f"âŒ æ•°æ®é›† {dataset_name} æ„å»ºå¤±è´¥")
            
    except Exception as e:
        print(f"âŒ ä¸‹è½½ {dataset_name} æ—¶å‡ºé”™: {e}")
        
        # å¦‚æœHuggingFaceå¤±è´¥ï¼Œå°è¯•modelscope
        print("\n=== å°è¯•ä½¿ç”¨modelscopeä¸‹è½½ ===")
        os.environ['VLMEVALKIT_USE_MODELSCOPE'] = '1'
        
        try:
            dataset = build_dataset(dataset_name)
            if dataset is not None:
                print(f"âœ… æˆåŠŸé€šè¿‡modelscopeæ„å»ºGQAæ•°æ®é›†: {dataset_name}")
                print(f"   æ•°æ®é›†ç±»å‹: {dataset.TYPE}")
                print(f"   æ•°æ®é›†æ¨¡æ€: {dataset.MODALITY}")
                print(f"   æ•°æ®é›†å¤§å°: {len(dataset.data)}")
                return dataset
            else:
                print(f"âŒ modelscopeä¸‹è½½ {dataset_name} ä¹Ÿå¤±è´¥")
        except Exception as e2:
            print(f"âŒ modelscopeä¸‹è½½ {dataset_name} æ—¶å‡ºé”™: {e2}")
    
    return None

if __name__ == "__main__":
    print("å¼€å§‹ä¸‹è½½GQA benchmark...")
    
    # ä¸‹è½½GQAæ•°æ®é›†
    gqa_dataset = download_gqa_dataset()
    
    if gqa_dataset is not None:
        print("\nğŸ‰ GQA benchmarkä¸‹è½½æˆåŠŸï¼")
        print(f"æ•°æ®é›†ä¿¡æ¯:")
        print(f"  - åç§°: {gqa_dataset.__class__.__name__}")
        print(f"  - ç±»å‹: {gqa_dataset.TYPE}")
        print(f"  - æ¨¡æ€: {gqa_dataset.MODALITY}")
        print(f"  - æ ·æœ¬æ•°: {len(gqa_dataset.data)}")
        
        # æ£€æŸ¥ç¼“å­˜ç›®å½•å†…å®¹
        cache_dir = os.environ['HF_HOME']
        print(f"\nç¼“å­˜ç›®å½•å†…å®¹:")
        if os.path.exists(cache_dir):
            for item in os.listdir(cache_dir):
                item_path = os.path.join(cache_dir, item)
                if os.path.isdir(item_path):
                    print(f"  ğŸ“ {item}")
                else:
                    print(f"  ğŸ“„ {item}")
    else:
        print("\nâŒ GQA benchmarkä¸‹è½½å¤±è´¥")
        print("è¯·æ£€æŸ¥:")
        print("  1. ç½‘ç»œè¿æ¥æ˜¯å¦æ­£å¸¸")
        print("  2. æ•°æ®é›†åç§°æ˜¯å¦æ­£ç¡®")
        print("  3. æ˜¯å¦æœ‰è¶³å¤Ÿçš„ç£ç›˜ç©ºé—´")
        
        # æ˜¾ç¤ºæ‰€æœ‰æ”¯æŒçš„æ•°æ®é›†
        print("\nå½“å‰æ”¯æŒçš„æ•°æ®é›†åˆ—è¡¨:")
        from vlmeval.dataset import SUPPORTED_DATASETS
        all_datasets = sorted(SUPPORTED_DATASETS)
        print(f"æ€»å…±æ”¯æŒ {len(all_datasets)} ä¸ªæ•°æ®é›†")
        
        # æ˜¾ç¤ºå‰20ä¸ªæ•°æ®é›†ä½œä¸ºå‚è€ƒ
        print("\néƒ¨åˆ†æ”¯æŒçš„æ•°æ®é›†:")
        for i, name in enumerate(all_datasets[:20]):
            print(f"  {i+1:2d}. {name}")